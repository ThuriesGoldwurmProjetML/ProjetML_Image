{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as to\n",
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_goldStandard = pd.read_csv('data/annotations/gold_standard.csv')\n",
    "df_goldStandard['nb_abnormality'] =  df_goldStandard.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1dAVb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBBB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBBB</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_abnormality</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  \\\n",
       "1dAVb           0  0  0  0  0  0  0  0  0  0   0   0   1   0   0   1   0   0   \n",
       "RBBB            0  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   \n",
       "LBBB            0  1  0  0  0  0  0  0  0  0   0   0   0   0   0   1   0   0   \n",
       "SB              0  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   \n",
       "AF              0  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   \n",
       "ST              0  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   \n",
       "nb_abnormality  0  1  0  0  0  0  0  0  0  0   0   0   1   0   0   2   0   0   \n",
       "\n",
       "                18  19  \n",
       "1dAVb            1   0  \n",
       "RBBB             0   0  \n",
       "LBBB             1   0  \n",
       "SB               0   0  \n",
       "AF               0   0  \n",
       "ST               0   0  \n",
       "nb_abnormality   2   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_goldStandard.shape)\n",
    "display(df_goldStandard.head(20).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 4096, 12)]\n",
      "(None, 4096, 64)\n",
      "(None, 4096, 64)\n",
      "(None, 4096, 64)\n",
      "(None, 4096, 128)\n",
      "(None, 4096, 128)\n",
      "(None, 4096, 128)\n",
      "(None, 4096, 128)\n",
      "(None, 1024, 64)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 196)\n",
      "(None, 1024, 196)\n",
      "(None, 1024, 196)\n",
      "(None, 1024, 196)\n",
      "(None, 256, 128)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 256)\n",
      "(None, 256, 256)\n",
      "(None, 256, 256)\n",
      "(None, 256, 256)\n",
      "(None, 64, 196)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 320)\n",
      "(None, 64, 320)\n",
      "(None, 64, 320)\n",
      "(None, 64, 320)\n",
      "(None, 16, 256)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 5120)\n",
      "(None, 6)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "signal (InputLayer)             [(None, 4096, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4096, 64)     12288       signal[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4096, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4096, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4096, 128)    131072      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4096, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4096, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096, 128)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1024, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1024, 128)    262144      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1024, 128)    8192        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1024, 128)    0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024, 128)    512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1024, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024, 128)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1024, 196)    401408      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024, 196)    784         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1024, 196)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024, 196)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 256, 128)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 256, 196)     614656      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 256, 196)     25088       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 196)     0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 196)     784         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 196)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 196)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 256, 256)     802816      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256)     1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 256)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 64, 196)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 256)      1048576     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 256)      50176       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 256)      0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 256)      1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 256)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 256)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 320)      1310720     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 320)      1280        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 320)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 320)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 16, 256)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 16, 320)      1638400     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 16, 320)      81920       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 320)      0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 320)      1280        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 320)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 320)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5120)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 6)            30726       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,425,638\n",
      "Trainable params: 6,421,910\n",
      "Non-trainable params: 3,728\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = load_model(f\"model/model.hdf5\", compile=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "for layer in model.layers:\n",
    "  print(layer.output_shape)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "signal (InputLayer)             [(None, 4096, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 4096, 64)     12288       signal[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4096, 64)     256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4096, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 4096, 128)    131072      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4096, 128)    512         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4096, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4096, 128)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1024, 64)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1024, 128)    262144      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1024, 128)    8192        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1024, 128)    0           conv1d_16[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1024, 128)    512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1024, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024, 128)    0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1024, 196)    401408      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1024, 196)    784         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1024, 196)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1024, 196)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 256, 128)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 256, 196)     614656      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 256, 196)     25088       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 196)     0           conv1d_19[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256, 196)     784         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 256, 196)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 256, 196)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 256, 256)     802816      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256)     1024        conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256, 256)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 64, 196)      0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 64, 256)      1048576     dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 64, 256)      50176       max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 256)      0           conv1d_22[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 256)      1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 256)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64, 256)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 64, 320)      1310720     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 320)      1280        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 320)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64, 320)      0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 16, 256)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16, 320)      1638400     dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 16, 320)      81920       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 320)      0           conv1d_25[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 320)      1280        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 320)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 320)      0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5120)         0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            30726       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,425,638\n",
      "Trainable params: 6,421,910\n",
      "Non-trainable params: 3,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Activation, Add, Flatten, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ResidualUnit(object):\n",
    "    \"\"\"Residual unit block (unidimensional).\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples_out: int\n",
    "        Number of output samples.\n",
    "    n_filters_out: int\n",
    "        Number of output filters.\n",
    "    kernel_initializer: str, optional\n",
    "        Initializer for the weights matrices. See Keras initializers. By default it uses\n",
    "        'he_normal'.\n",
    "    dropout_keep_prob: float [0, 1), optional\n",
    "        Dropout rate used in all Dropout layers. Default is 0.8\n",
    "    kernel_size: int, optional\n",
    "        Kernel size for convolutional layers. Default is 17.\n",
    "    preactivation: bool, optional\n",
    "        When preactivation is true use full preactivation architecture proposed\n",
    "        in [1]. Otherwise, use architecture proposed in the original ResNet\n",
    "        paper [2]. By default it is true.\n",
    "    postactivation_bn: bool, optional\n",
    "        Defines if you use batch normalization before or after the activation layer (there\n",
    "        seems to be some advantages in some cases:\n",
    "        https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md).\n",
    "        If true, the batch normalization is used before the activation\n",
    "        function, otherwise the activation comes first, as it is usually done.\n",
    "        By default it is false.\n",
    "    activation_function: string, optional\n",
    "        Keras activation function to be used. By default 'relu'.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] K. He, X. Zhang, S. Ren, and J. Sun, \"Identity Mappings in Deep Residual Networks,\"\n",
    "           arXiv:1603.05027 [cs], Mar. 2016. https://arxiv.org/pdf/1603.05027.pdf.\n",
    "    .. [2] K. He, X. Zhang, S. Ren, and J. Sun, \"Deep Residual Learning for Image Recognition,\" in 2016 IEEE Conference\n",
    "           on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778. https://arxiv.org/pdf/1512.03385.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_samples_out, n_filters_out, kernel_initializer='he_normal',\n",
    "                 dropout_keep_prob=0.8, kernel_size=17, preactivation=True,\n",
    "                 postactivation_bn=False, activation_function='relu'):\n",
    "        self.n_samples_out = n_samples_out\n",
    "        self.n_filters_out = n_filters_out\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout_rate = 1 - dropout_keep_prob\n",
    "        self.kernel_size = kernel_size\n",
    "        self.preactivation = preactivation\n",
    "        self.postactivation_bn = postactivation_bn\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def _skip_connection(self, y, downsample, n_filters_in):\n",
    "        \"\"\"Implement skip connection.\"\"\"\n",
    "        # Deal with downsampling\n",
    "        if downsample > 1:\n",
    "            y = MaxPooling1D(downsample, strides=downsample, padding='same')(y)\n",
    "        elif downsample == 1:\n",
    "            y = y\n",
    "        else:\n",
    "            raise ValueError(\"Number of samples should always decrease.\")\n",
    "        # Deal with n_filters dimension increase\n",
    "        if n_filters_in != self.n_filters_out:\n",
    "            # This is one of the two alternatives presented in ResNet paper\n",
    "            # Other option is to just fill the matrix with zeros.\n",
    "            y = Conv1D(self.n_filters_out, 1, padding='same',\n",
    "                       use_bias=False, kernel_initializer=self.kernel_initializer)(y)\n",
    "        return y\n",
    "\n",
    "    def _batch_norm_plus_activation(self, x):\n",
    "        if self.postactivation_bn:\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            x = BatchNormalization(center=False, scale=False)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(self.activation_function)(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"Residual unit.\"\"\"\n",
    "        x, y = inputs\n",
    "        n_samples_in = y.shape[1]\n",
    "        downsample = n_samples_in // self.n_samples_out\n",
    "        n_filters_in = y.shape[2]\n",
    "        y = self._skip_connection(y, downsample, n_filters_in)\n",
    "        # 1st layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, padding='same',\n",
    "                   use_bias=False, kernel_initializer=self.kernel_initializer)(x)\n",
    "        x = self._batch_norm_plus_activation(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # 2nd layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, strides=downsample,\n",
    "                   padding='same', use_bias=False,\n",
    "                   kernel_initializer=self.kernel_initializer)(x)\n",
    "        if self.preactivation:\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            y = x\n",
    "            x = self._batch_norm_plus_activation(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "            y = x\n",
    "        return [x, y]\n",
    "\n",
    "\n",
    "def get_model(n_classes, last_layer='sigmoid'):\n",
    "    kernel_size = 16\n",
    "    kernel_initializer = 'he_normal'\n",
    "    signal = Input(shape=(4096, 12), dtype=np.float32, name='signal')\n",
    "    x = signal\n",
    "    x = Conv1D(64, kernel_size, padding='same', use_bias=False,\n",
    "               kernel_initializer=kernel_initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x, y = ResidualUnit(1024, 128, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, x])\n",
    "    x, y = ResidualUnit(256, 196, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, y = ResidualUnit(64, 256, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, _ = ResidualUnit(16, 320, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x = Flatten()(x)\n",
    "    diagn = Dense(n_classes, activation=last_layer, kernel_initializer=kernel_initializer)(x)\n",
    "    model = Model(signal, diagn)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = get_model(6)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
